<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Speech-to-Text and Summarization</title>
    
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: black;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            text-align: center;
            flex-direction: column;
        }
        h1 {
            font-size: 36px;
        }
        #output, #summary, #expanded, #concept-map {
            margin-top: 20px;
            font-size: 18px;
            font-weight: bold;
        }
        button {
            padding: 10px 20px;
            background-color: #ff9900;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:hover {
            background-color: #e68900;
        }
    </style>
</head>
<body>

    <h1>Test AI Speech-to-Text and Summarization</h1>
    
    <button id="start-recording">Start Recording</button>
    
    <div id="output">Transcribed text will appear here.</div>
    <div id="summary">Summary will appear here.</div>
    <div id="expanded">Expanded ideas will appear here.</div>
    <div id="concept-map">Concept map will appear here.</div>

    <script>
        // Step 1: Implement Speech-to-Text (Whisper)

        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = true;
        recognition.lang = 'en-US';

        // When the user clicks the button to start speaking
        document.getElementById('start-recording').addEventListener('click', () => {
            recognition.start();
            console.log('Recording started');
            updateStatus("Listening...");
        });

        // Capture results and display in real-time
        recognition.onresult = function(event) {
            const transcript = event.results[event.results.length - 1][0].transcript;
            document.getElementById('output').innerText = `You said: ${transcript}`;

            // Step 2: Pass the transcription to Mistral for summarization and expansion
            processTranscription(transcript);
        };

        recognition.onerror = function(event) {
            console.error('Speech recognition error:', event.error);
            updateStatus("Error: " + event.error);
        };

        // Function to handle the transcription process
        function processTranscription(text) {
            // Step 2a: Summarize the transcribed text
            const summarizedText = summarizeText(text);
            // Step 2b: Expand on the transcribed idea
            const expandedText = expandText(summarizedText);

            // Display summarized and expanded text
            document.getElementById('summary').innerText = `Summary: ${summarizedText}`;
            document.getElementById('expanded').innerText = `Expanded: ${expandedText}`;

            // Step 3: Generate Concept Map from expanded text
            generateConceptMap(expandedText);
        }

        // Placeholder: Summarize the text using Mistral
        function summarizeText(text) {
            // Call Mistral AI API for summarization (Placeholder)
            return `Summarized: ${text.slice(0, 50)}...`; // Simple truncation for demo
        }

        // Placeholder: Expand the idea using Mistral
        function expandText(text) {
            // Call Mistral AI API for expansion (Placeholder)
            return `Expanded idea based on: ${text}`; // Simple expansion for demo
        }

        // Step 3: Concept Mapping (Related Ideas & Mind Mapping)
        function generateConceptMap(text) {
            // Call Mistral AI or use a logic to find related ideas (Placeholder)
            const concepts = ["Related Concept 1", "Related Concept 2", "Related Concept 3"];
            document.getElementById('concept-map').innerText = `Related Concepts: ${concepts.join(', ')}`;
        }

        // Step 4: Text-to-Speech with Adaptive Speed (Using Web Speech API)
        function speakText(text) {
            const speech = new SpeechSynthesisUtterance(text);
            speech.rate = 1;  // Adjust speed dynamically based on text complexity
            window.speechSynthesis.speak(speech);
        }

        // Step 5: Visualize AI Process
        function updateStatus(status) {
            document.getElementById('output').innerText = status;
        }

    </script>
</body>
</html>
